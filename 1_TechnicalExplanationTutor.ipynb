{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a tool that takes a technical question, and responds with an explanation from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "api_key_gpt = os.getenv('OPENAI_API_KEY') #OPENAI_API_KEY is in Path variable on local machine\n",
    "if api_key_gpt and api_key_gpt.startswith('sk-proj-') and len(api_key_gpt)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "openai = OpenAI()\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\" #url on local box\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a technical expert.  You will be asked a question \\\n",
    "    either about some code or some other computer or software related question. \\\n",
    "    Please analyze and provide a succinct analysis or explanation , in as simple of terms of possible, of what the \\\n",
    "    user is asking.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just replace this text to ask something new\n",
    "user_question = \"\"\" \n",
    "    Can you explain what purpose 'yield' serves in the python code:\n",
    "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In Python, `yield` is used in functions to make them generators. A generator is a type of iterable that allows you to iterate over a sequence of values without storing the entire sequence in memory at once.\n",
       "\n",
       "In the code you provided:\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "Here's what each part means:\n",
       "\n",
       "1. **`yield from`**: This keyword is used to yield all values from an iterable one at a time. It allows the function to delegate part of its operations to another iterable (in this case, a set comprehension).\n",
       "\n",
       "2. **`{book.get(\"author\") for book in books if book.get(\"author\")}`**: This is a set comprehension that creates a set of authors from a list of `books`. It goes through each `book`, retrieves the author using `book.get(\"author\")`, and includes this author in the set only if it's not `None`.\n",
       "\n",
       "Summarizing, the entire line will produce each distinct author of the books in the `books` list, one at a time, when iterating through the generator. This allows for memory-efficient handling of potentially large datasets while also ensuring that you only work with unique authors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Gpt 4o-mini answer w/streaming\n",
    "stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_question}\n",
    "          ],\n",
    "        stream=True #This allows data to 'flow' back in chunks, rather than a single text of response\n",
    "    )\n",
    "#Initialize empty response\n",
    "response = \"\"\n",
    "\n",
    "display_handle = display(Markdown(\"\"), display_id=True) #empty markdown element\n",
    "for chunk in stream: # as data arrives\n",
    "    response += chunk.choices[0].delta.content or '' #extract text from response chunk, where delta contains only the newest part of the response\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\") #Ensure we don't add None but rather an empty string\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Explanation of `yield`**\n",
       "\n",
       "In Python 3, the `yield` keyword is used to define generators. A generator is a special type of iterable that can be used to generate a sequence of values on-the-fly, rather than computing them all at once and storing them in memory.\n",
       "\n",
       "When you use `yield`, you're essentially creating a function that produces a value and then pauses its execution, returning control back to the caller. The next time the function is called, it resumes from where it left off, yielding another value, and so on.\n",
       "\n",
       "**In this specific code**\n",
       "\n",
       "The line `yield from {book.get(\"author\") for book in books if book.get(\"author\")}` uses a feature of Python 3.5+ called \"yield from\" to delegate the generation of values to an existing iterator.\n",
       "\n",
       "Here's what's happening:\n",
       "\n",
       "1. `{book.get(\"author\") for book in books if book.get(\"author\")}` is a generator expression that iterates over the `books` list, filters out items with no author, and yields their authors.\n",
       "2. `yield from ...` takes the result of the generator expression (an iterator) and \"yields from\" it, effectively delegating its generation of values to this new iterator.\n",
       "\n",
       "In essence, this code is saying: \"Take the filtered book authors and yield them one by one, without storing them all in memory at once.\"\n",
       "\n",
       "**Benefits**\n",
       "\n",
       "This approach has several advantages:\n",
       "\n",
       "* Memory efficiency: We're not creating a large list or dictionary to store the authors; instead, we generate them on-the-fly.\n",
       "* Flexibility: This code can be used with any iterable (like a database query result) that produces author values.\n",
       "\n",
       "In summary, `yield` in this context allows us to lazily generate and yield book authors without storing them all in memory at once."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#llama3.2 to answer\n",
    "response = ollama.chat(\n",
    "        model = MODEL_LLAMA,\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    "    )\n",
    "print(display(Markdown(response['message']['content'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "llms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
